# Model Configurations for Landmark-Based Hand Gesture Recognition
# Configuration for SVM, Random Forest, and MLP models

# Support Vector Machine Configuration
svm:
  model_type: "SVM"
  parameters:
    # Kernel type: 'linear', 'poly', 'rbf', 'sigmoid'
    kernel: 'rbf'
    # Regularization parameter
    C: 1.0
    # Kernel coefficient for 'rbf', 'poly', 'sigmoid'
    gamma: 'scale'
    # Whether to use probability estimates
    probability: true
    # Random state for reproducibility
    random_state: 42
    # Maximum number of iterations
    max_iter: 1000
  
  # Feature preprocessing
  preprocessing:
    # Standardize features (recommended for SVM)
    standardize: true
    # Principal Component Analysis
    pca:
      enabled: false
      n_components: 0.95  # Keep 95% of variance
  
  # Training parameters
  training:
    # Cross-validation folds for hyperparameter tuning
    cv_folds: 5
    # Grid search parameters (optional)
    grid_search:
      enabled: true
      param_grid:
        C: [0.1, 1.0, 10.0, 100.0]
        gamma: ['scale', 'auto', 0.001, 0.01, 0.1, 1.0]
        kernel: ['rbf', 'linear']

# Random Forest Configuration
random_forest:
  model_type: "RandomForest"
  parameters:
    # Number of trees in the forest
    n_estimators: 100
    # Maximum depth of the tree
    max_depth: null  # No limit
    # Minimum samples required to split an internal node
    min_samples_split: 2
    # Minimum samples required to be at a leaf node
    min_samples_leaf: 1
    # Number of features to consider for the best split
    max_features: 'sqrt'  # sqrt(n_features)
    # Bootstrap samples when building trees
    bootstrap: true
    # Random state for reproducibility
    random_state: 42
    # Number of jobs to run in parallel
    n_jobs: -1  # Use all available cores
  
  # Feature preprocessing
  preprocessing:
    # Standardization (less critical for tree-based models)
    standardize: false
    # PCA
    pca:
      enabled: false
      n_components: 0.95
  
  # Training parameters
  training:
    cv_folds: 5
    grid_search:
      enabled: true
      param_grid:
        n_estimators: [50, 100, 200]
        max_depth: [null, 10, 20, 30]
        min_samples_split: [2, 5, 10]
        max_features: ['sqrt', 'log2', null]

# Global training settings
global_settings:
  # Evaluation metrics to compute
  metrics:
    - accuracy
    - precision
    - recall
    - f1_score
    - confusion_matrix
    - classification_report
  
  # Cross-validation settings
  cross_validation:
    # Stratified to maintain class distribution
    stratified: true
    # Number of folds for model evaluation
    cv_folds: 5
    # Random state for CV splits
    random_state: 42
  
  # Output settings
  output:
    # Save trained models
    save_models: true
    # Save evaluation results
    save_results: true
    # Verbose output during training
    verbose: true
    # Generate plots (ROC curves, confusion matrices)
    generate_plots: true
  
  # Feature engineering
  feature_engineering:
    # Use hand landmark distances between specific points
    use_distances: true
    # Use angles between landmark triplets
    use_angles: true
    # Use landmark velocities (requires temporal data)
    use_velocities: false
    # Normalize landmark coordinates relative to hand center
    normalize_coordinates: true

# Dataset-specific settings
dataset:
  # Gesture classes in OUHANDS
  classes: ['A', 'B', 'C', 'D', 'E', 'F', 'H', 'I', 'J', 'K']
  # Number of hand landmarks from MediaPipe
  n_landmarks: 21
  # Coordinate dimensions (x, y, z)
  coordinate_dims: 3
  # Total feature dimension (21 landmarks * 3 coordinates = 63)
  base_feature_dim: 63